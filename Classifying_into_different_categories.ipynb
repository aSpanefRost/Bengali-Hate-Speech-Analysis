{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Using LR, NB, SVM, KNN, RF, GBT  classifier to classify texts into different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import newaxis as na\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize  \n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import csv \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('bengali_hate_v2.0.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5698, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4698, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=df[:4698]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=df[4698:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>ছিঃ ছিঃ মিথিলা এতো রুচিহীন জঘন্য</td>\n",
       "      <td>Personal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>নাস্তিক বা হিন্দুরা আপনার এই ধরনের বক্তব্য শুন...</td>\n",
       "      <td>Religious</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>তোমরা ব্যবসার জন্য ধর্মকে কেন্দ্র করে এইগুলো য...</td>\n",
       "      <td>Religious</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>পুলিশের নির্বিচার গুলি বর্ষণে পাখির মত মরছে মা...</td>\n",
       "      <td>Geopolitical</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>আপনারা যারা এতবাজে কমেন্ট করেছেন যে আপনারা মুস...</td>\n",
       "      <td>Religious</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text         label  target\n",
       "4698                  ছিঃ ছিঃ মিথিলা এতো রুচিহীন জঘন্য       Personal       0\n",
       "4699  নাস্তিক বা হিন্দুরা আপনার এই ধরনের বক্তব্য শুন...     Religious       2\n",
       "4700  তোমরা ব্যবসার জন্য ধর্মকে কেন্দ্র করে এইগুলো য...     Religious       2\n",
       "4701  পুলিশের নির্বিচার গুলি বর্ষণে পাখির মত মরছে মা...  Geopolitical       3\n",
       "4702  আপনারা যারা এতবাজে কমেন্ট করেছেন যে আপনারা মুস...     Religious       2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words='stopwords-bn.txt'\n",
    "text_data=[]\n",
    "\n",
    "with open(stop_words,'r',encoding='utf-8') as temp_output_file:\n",
    "    reader=csv.reader(temp_output_file, delimiter='\\n')\n",
    "    for row in reader:\n",
    "        text_data.append(row)\n",
    "stop_word_list=[x[0] for x in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_word_list)  \n",
    "\n",
    "def textCleaner(example_sent): \n",
    "    word_tokens = word_tokenize(example_sent)  \n",
    "    #filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_train = TreebankWordDetokenizer().detokenize(word_tokens)\n",
    "\n",
    "    return filtered_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test = test['text'].apply(textCleaner)\n",
    "filtered_train = train['text'].apply(textCleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Personal        1850\n",
       "Geopolitical    1408\n",
       "Religious        778\n",
       "Political        662\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = filtered_train, train['target'].values\n",
    "x_test, y_test = filtered_test, test['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = CountVectorizer()\n",
    "x_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "x_test = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.65      0.73      0.68       339\n",
      "Geopolitical       0.54      0.46      0.50       152\n",
      "   Religious       0.58      0.55      0.56       179\n",
      "   Political       0.70      0.68      0.69       330\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.62      0.60      0.61      1000\n",
      "weighted avg       0.64      0.64      0.64      1000\n",
      "\n",
      "MCC: 0.4947396978672513\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha = 0.1)\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.44      0.94      0.60       339\n",
      "Geopolitical       0.53      0.05      0.10       152\n",
      "   Religious       0.66      0.17      0.27       179\n",
      "   Political       0.87      0.57      0.69       330\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.63      0.43      0.42      1000\n",
      "weighted avg       0.64      0.55      0.50      1000\n",
      "\n",
      "MCC: 0.39575848065112784\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.58      0.81      0.68       339\n",
      "Geopolitical       0.53      0.32      0.40       152\n",
      "   Religious       0.63      0.61      0.62       179\n",
      "   Political       0.78      0.63      0.70       330\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.63      0.59      0.60      1000\n",
      "weighted avg       0.65      0.64      0.63      1000\n",
      "\n",
      "MCC: 0.4991882985833123\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's run the model and get its accuracy score\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC(kernel=\"linear\", degree=5, probability=True) # 0.9306853582554517\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.45      0.14      0.22       339\n",
      "Geopolitical       0.19      0.70      0.30       152\n",
      "   Religious       0.28      0.35      0.31       179\n",
      "   Political       0.52      0.16      0.24       330\n",
      "\n",
      "    accuracy                           0.27      1000\n",
      "   macro avg       0.36      0.34      0.27      1000\n",
      "weighted avg       0.40      0.27      0.26      1000\n",
      "\n",
      "MCC: 0.11354356701498186\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train.toarray(), y_train)\n",
    "\n",
    "y_pred = gnb.predict(x_test.toarray())\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.59      0.81      0.68       339\n",
      "Geopolitical       0.52      0.33      0.40       152\n",
      "   Religious       0.63      0.54      0.58       179\n",
      "   Political       0.79      0.69      0.74       330\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.63      0.59      0.60      1000\n",
      "weighted avg       0.65      0.65      0.64      1000\n",
      "\n",
      "MCC: 0.510773364956144\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.60      0.68      0.64       339\n",
      "Geopolitical       0.47      0.38      0.42       152\n",
      "   Religious       0.55      0.57      0.56       179\n",
      "   Political       0.69      0.64      0.67       330\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.58      0.57      0.57      1000\n",
      "weighted avg       0.60      0.60      0.60      1000\n",
      "\n",
      "MCC: 0.4469684344554203\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.62      0.82      0.71       339\n",
      "Geopolitical       0.62      0.36      0.46       152\n",
      "   Religious       0.66      0.61      0.64       179\n",
      "   Political       0.79      0.70      0.74       330\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.67      0.62      0.64      1000\n",
      "weighted avg       0.68      0.68      0.67      1000\n",
      "\n",
      "MCC: 0.5474998302901893\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.59      0.88      0.71       339\n",
      "Geopolitical       0.61      0.30      0.40       152\n",
      "   Religious       0.68      0.60      0.64       179\n",
      "   Political       0.84      0.67      0.74       330\n",
      "\n",
      "    accuracy                           0.67      1000\n",
      "   macro avg       0.68      0.61      0.62      1000\n",
      "weighted avg       0.69      0.67      0.66      1000\n",
      "\n",
      "MCC: 0.5494291482603195\n"
     ]
    }
   ],
   "source": [
    "gbt = GradientBoostingClassifier(random_state=0, n_estimators=200)\n",
    "gbt.fit(x_train, y_train)\n",
    "y_pred = gbt.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Personal       0.59      0.81      0.69       339\n",
      "Geopolitical       0.54      0.34      0.41       152\n",
      "   Religious       0.61      0.59      0.60       179\n",
      "   Political       0.81      0.65      0.72       330\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.64      0.60      0.61      1000\n",
      "weighted avg       0.66      0.65      0.64      1000\n",
      "\n",
      "MCC: 0.512066397619003\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(random_state=0, n_estimators=200)\n",
    "ab.fit(x_train, y_train)\n",
    "y_pred = ab.predict(x_test)\n",
    "\n",
    "categories = ['Personal', 'Geopolitical','Religious','Political']\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
